---
phase: 02-testing-infrastructure
plan: 03
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - tests/test_chunking.py
  - tests/test_language.py
autonomous: true

must_haves:
  truths:
    - "Chunking disabled for 0, 1, 5 commits"
    - "Chunking enabled for 6+ commits"
    - "Chunking produces correct number of chunks for 100+ commits"
    - "All 5 supported languages return correct configuration"
    - "Unsupported language triggers fallback warning"
    - "Language fallback uses English configuration"
  artifacts:
    - path: "tests/test_chunking.py"
      provides: "Chunking algorithm boundary tests"
      min_lines: 60
    - path: "tests/test_language.py"
      provides: "Language configuration tests"
      min_lines: 50
  key_links:
    - from: "tests/test_chunking.py"
      to: "src/generate_changelog.py"
      via: "imports process_commits_in_chunks"
      pattern: "process_commits_in_chunks"
    - from: "tests/test_language.py"
      to: "src/generate_changelog.py"
      via: "imports language_configs"
      pattern: "language_configs"
---

<objective>
Create tests for chunking algorithm and language configuration

Purpose: Validate chunking boundary conditions (TEST-03) and language configuration lookup with fallback (TEST-05). These are pure functions with clear inputs/outputs, ideal for parametrized testing.
Output: test_chunking.py with 6-8 tests, test_language.py with 6-8 tests
</objective>

<execution_context>
@/Users/robertfridzema/.claude/get-shit-done/workflows/execute-plan.md
@/Users/robertfridzema/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-testing-infrastructure/02-CONTEXT.md
@.planning/phases/02-testing-infrastructure/02-RESEARCH.md
@src/generate_changelog.py
@tests/conftest.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create test_chunking.py for chunking algorithm</name>
  <files>tests/test_chunking.py</files>
  <action>
Create `tests/test_chunking.py` with tests for `process_commits_in_chunks()` function.

**Key insight from source code:**
- COMMITS_PER_CHUNK = 5
- use_chunking = total_commits > COMMITS_PER_CHUNK (so >5 triggers chunking)
- process_commits_in_chunks() takes raw commits string and chunk_size parameter

1. **test_process_empty_commits**: Empty string input
   - Input: ""
   - Assert returns ([], []) - empty lists

2. **test_process_single_commit**: One commit (below threshold)
   - Input: "abc123|feat: Test|Author|2024-01-01|abc"
   - Assert returns lists with 1 formatted commit and 1 link

3. **test_process_five_commits**: Exactly at threshold (5)
   - Input: 5 pipe-delimited commits
   - Assert returns lists with 5 items each

4. **test_process_six_commits**: Just above threshold (6)
   - Input: 6 commits
   - Assert returns lists with 6 items each
   - NOTE: process_commits_in_chunks doesn't decide chunking - it just processes. The chunking decision is in main code.

5. **test_process_hundred_commits**: Large set (100)
   - Generate 100 commits
   - Assert returns lists with 100 items each

6. **test_process_malformed_commit**: Commit without proper delimiters
   - Input: "some random text without pipes"
   - Assert gracefully handles (returns formatted version)

7. **test_process_commit_with_special_chars**: Unicode and special characters
   - Input: commit with emojis, unicode chars in subject
   - Assert properly formatted

8. **test_chunking_decision_boundary**: Test the global chunking decision logic
   - Test that use_chunking = total_commits > COMMITS_PER_CHUNK
   - Verify boundary at 5/6 commits
   - This tests the logic, not the function

Use @pytest.mark.parametrize for boundary conditions:
```python
@pytest.mark.parametrize("num_commits,expected_count", [
    (0, 0),
    (1, 1),
    (5, 5),
    (6, 6),
    (100, 100),
])
def test_process_commits_count(num_commits, expected_count):
    ...
```
  </action>
  <verify>
```bash
pytest tests/test_chunking.py -v
```
All tests should pass.
  </verify>
  <done>
- tests/test_chunking.py contains 6-8 tests
- All tests pass
- Tests cover: empty, single, threshold (5), above threshold (6), large (100), malformed, special chars
- Parametrized tests for clean boundary testing
  </done>
</task>

<task type="auto">
  <name>Task 2: Create test_language.py for language configuration</name>
  <files>tests/test_language.py</files>
  <action>
Create `tests/test_language.py` with tests for language configuration lookup.

**Key insight from source code:**
- language_configs dict contains: English, Dutch, German, French, Spanish
- Each config has keys: week_label, generated_on, commits_label, tech_changes, user_impact, all_commits, statistics, file_changes, changelog_title, auto_updated, fallback_tech, fallback_business, lines_added, lines_deleted, files_changed, force_updated
- Unsupported language prints warning and falls back to English

1. **test_english_config**: English returns correct config
   - Assert week_label = "Week"
   - Assert tech_changes = "Technical Changes" (with emoji)

2. **test_dutch_config**: Dutch returns correct config
   - Assert week_label = "Week"
   - Assert tech_changes = "Technische wijzigingen" (with emoji)

3. **test_german_config**: German returns correct config
   - Assert week_label = "Woche"
   - Assert tech_changes = "Technische Anderungen" (with emoji)

4. **test_french_config**: French returns correct config
   - Assert week_label = "Semaine"
   - Assert tech_changes = "Modifications techniques" (with emoji)

5. **test_spanish_config**: Spanish returns correct config
   - Assert week_label = "Semana"
   - Assert tech_changes = "Cambios tecnicos" (with emoji)

6. **test_all_languages_have_required_keys**: Verify all languages have same keys
   - For each language in language_configs
   - Assert all expected keys present

7. **test_unsupported_language_fallback** (requires module reload):
   - Set OUTPUT_LANGUAGE = "Klingon"
   - Reload module
   - Capture stdout (capsys)
   - Assert warning message printed
   - Assert config equals English config

8. **test_case_sensitive_language_lookup**: Verify exact match required
   - "english" (lowercase) should trigger fallback
   - Only "English" (capitalized) works

Use @pytest.mark.parametrize for the 5 languages:
```python
@pytest.mark.parametrize("language,expected_week_label", [
    ("English", "Week"),
    ("Dutch", "Week"),
    ("German", "Woche"),
    ("French", "Semaine"),
    ("Spanish", "Semana"),
])
def test_language_week_labels(language, expected_week_label):
    from src.generate_changelog import language_configs
    assert language_configs[language]["week_label"] == expected_week_label
```

NOTE: The fallback test requires reloading the module to trigger the warning code path. Use importlib.reload().
  </action>
  <verify>
```bash
pytest tests/test_language.py -v
```
All tests should pass.
  </verify>
  <done>
- tests/test_language.py contains 6-8 tests
- All tests pass
- Tests cover: all 5 languages, required keys, unsupported fallback, case sensitivity
- Parametrized tests for all language configs
  </done>
</task>

</tasks>

<verification>
```bash
# Run both test files
pytest tests/test_chunking.py tests/test_language.py -v

# Verify test counts
pytest tests/test_chunking.py tests/test_language.py --collect-only | tail -5
```

Expected: 12-16 tests pass across both files.
</verification>

<success_criteria>
1. test_chunking.py has 6-8 passing tests covering boundary conditions
2. test_language.py has 6-8 passing tests covering all 5 languages + fallback
3. Parametrized tests used for clean, DRY test code
4. Fallback warning test captures stdout and verifies message
5. No module import issues (env vars set via conftest.py)
</success_criteria>

<output>
After completion, create `.planning/phases/02-testing-infrastructure/02-03-SUMMARY.md`
</output>
