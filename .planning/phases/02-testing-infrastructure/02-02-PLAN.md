---
phase: 02-testing-infrastructure
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - tests/test_retry.py
  - tests/test_redaction.py
autonomous: true

must_haves:
  truths:
    - "Retry decorator handles 429 rate limit with exponential backoff"
    - "Retry decorator fails immediately on 401 auth errors without retry"
    - "Retry decorator fails immediately on 404 model not found without retry"
    - "Retry decorator retries on network/timeout errors with backoff"
    - "Retry decorator exhausts retries and raises on persistent failures"
    - "API key redaction removes full key from error messages"
    - "API key redaction handles sk-or-* patterns in messages"
  artifacts:
    - path: "tests/test_retry.py"
      provides: "Retry decorator tests for all error conditions"
      min_lines: 100
    - path: "tests/test_redaction.py"
      provides: "API key redaction tests"
      min_lines: 30
  key_links:
    - from: "tests/test_retry.py"
      to: "src/generate_changelog.py"
      via: "imports retry_api_call decorator"
      pattern: "from src.generate_changelog import retry_api_call"
    - from: "tests/test_redaction.py"
      to: "src/generate_changelog.py"
      via: "imports redact_api_key function"
      pattern: "from src.generate_changelog import redact_api_key"
---

<objective>
Create tests for retry decorator and API key redaction

Purpose: Validate the critical error handling paths (TEST-02) and security feature (SEC-01) that were fixed in Phase 1. These tests cover retry logic for all error conditions (429, 401, 404, timeout, network) and API key redaction.
Output: test_retry.py with 8-10 tests, test_redaction.py with 4-5 tests
</objective>

<execution_context>
@/Users/robertfridzema/.claude/get-shit-done/workflows/execute-plan.md
@/Users/robertfridzema/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-testing-infrastructure/02-CONTEXT.md
@.planning/phases/02-testing-infrastructure/02-RESEARCH.md
@src/generate_changelog.py
@tests/conftest.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create test_redaction.py for API key redaction</name>
  <files>tests/test_redaction.py</files>
  <action>
Create `tests/test_redaction.py` with tests for the `redact_api_key()` function:

1. **test_redact_full_api_key**: Test that a full API key in text is replaced with redacted version
   - Set OPENROUTER_API_KEY env var to a test key
   - Pass text containing the full key
   - Assert output shows only first 4 chars + "...[REDACTED]"

2. **test_redact_sk_or_pattern**: Test the regex pattern catches sk-or-* keys
   - Pass text containing "Error with sk-or-abc123xyz"
   - Assert output contains "sk-or-...[REDACTED]"

3. **test_redact_preserves_other_text**: Test non-key text is preserved
   - Pass text without API keys
   - Assert output equals input

4. **test_redact_handles_empty_key**: Test graceful handling when OPENROUTER_API_KEY is empty
   - Unset or set empty OPENROUTER_API_KEY
   - Pass text with sk-or-* pattern
   - Assert regex pattern still catches it

5. **test_redact_multiple_occurrences**: Test multiple key occurrences are all redacted
   - Pass text with key appearing twice
   - Assert both occurrences redacted

NOTE: Use monkeypatch.setenv/delenv to control OPENROUTER_API_KEY for each test.
  </action>
  <verify>
```bash
pytest tests/test_redaction.py -v
```
All 5 tests should pass.
  </verify>
  <done>
- tests/test_redaction.py contains 5 tests
- All tests pass
- Tests cover: full key redaction, pattern matching, text preservation, empty key handling, multiple occurrences
  </done>
</task>

<task type="auto">
  <name>Task 2: Create test_retry.py for retry decorator error conditions</name>
  <files>tests/test_retry.py</files>
  <action>
Create `tests/test_retry.py` with tests for the `retry_api_call` decorator:

**CRITICAL: Mock time.sleep to make tests instant.**

1. **test_retry_success_first_attempt**: Function succeeds on first try, no retries needed
   - Mock function returns value immediately
   - Assert called exactly once

2. **test_retry_rate_limit_429_then_success**: Rate limit, retry, succeed
   - side_effect: [Exception("Error 429"), "success"]
   - Assert function called twice, result is "success"
   - Assert time.sleep was called (exponential backoff)

3. **test_retry_rate_limit_exhaustion**: 429 errors exhaust all retries
   - side_effect: [Exception("429")] * 3 (all attempts fail)
   - Assert raises Exception with "Rate limit exceeded"
   - Assert function called 3 times (max_retries)

4. **test_retry_auth_error_401_no_retry**: Auth errors fail immediately
   - side_effect: Exception("401 Unauthorized")
   - Assert raises Exception with "Authentication error"
   - Assert function called exactly ONCE (no retries for auth)

5. **test_retry_model_not_found_404_no_retry**: Model errors fail immediately
   - side_effect: Exception("404 model not found")
   - Assert raises Exception with "Model availability error"
   - Assert function called exactly ONCE

6. **test_retry_payload_too_large_413**: Payload errors fail immediately
   - side_effect: Exception("413 entity too large")
   - Assert raises Exception with "Payload too large"
   - Assert function called exactly ONCE

7. **test_retry_timeout_then_success**: Timeout, retry, succeed
   - side_effect: [Exception("timeout"), "success"]
   - Assert function called twice
   - Assert result is "success"

8. **test_retry_network_error_exhaustion**: Network errors exhaust retries
   - side_effect: [Exception("connection error")] * 3
   - Assert raises Exception with "Network error"
   - Assert function called 3 times

9. **test_retry_generic_error_then_success**: Unknown error, retry, succeed
   - side_effect: [Exception("something went wrong"), "success"]
   - Assert function called twice

10. **test_retry_returns_none_when_all_succeed_without_return**: Edge case - function returns None legitimately
    - Mock function returns None
    - Assert result is None (not an error)

Implementation pattern:
```python
def test_retry_rate_limit_429_then_success(mocker):
    mock_sleep = mocker.patch('time.sleep')  # Make instant
    mock_func = mocker.Mock()
    mock_func.side_effect = [Exception("Error 429: Rate limit"), "success"]

    from src.generate_changelog import retry_api_call

    @retry_api_call(max_retries=3, delay=1)
    def api_call():
        return mock_func()

    result = api_call()
    assert result == "success"
    assert mock_func.call_count == 2
    assert mock_sleep.called  # Backoff happened
```
  </action>
  <verify>
```bash
pytest tests/test_retry.py -v
```
All 10 tests should pass.
  </verify>
  <done>
- tests/test_retry.py contains 10 tests
- All tests pass
- Tests cover: success, 429/rate limit, 401/auth, 404/model, 413/payload, timeout, network, generic, exhaustion
- time.sleep is mocked in all retry tests
  </done>
</task>

</tasks>

<verification>
```bash
# Run both test files
pytest tests/test_redaction.py tests/test_retry.py -v

# Check coverage on retry and redaction functions
pytest tests/test_redaction.py tests/test_retry.py --cov=src --cov-report=term-missing | grep -A5 "generate_changelog"
```

Expected: 15 tests pass, high coverage on retry_api_call and redact_api_key functions.
</verification>

<success_criteria>
1. test_redaction.py has 5 passing tests covering all redaction scenarios
2. test_retry.py has 10 passing tests covering all error conditions
3. No flaky tests (time.sleep mocked, no real delays)
4. Retry tests verify both success and exhaustion scenarios
5. Auth (401), model (404), payload (413) errors fail immediately without retry
</success_criteria>

<output>
After completion, create `.planning/phases/02-testing-infrastructure/02-02-SUMMARY.md`
</output>
